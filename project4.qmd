---
title: "Client Report - Can You Predict That?"
subtitle: "Course DS 250"
author: "jaison jonnakuti"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL

dwellings_ml = "https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv"
 
data = pd.read_csv(dwellings_ml)

```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

_A Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client._

## QUESTION|TASK 1

__Create 2-3 charts that evaluate potential relationships between the home variables and `before1980`.__ Explain what you learn from the charts that could help a machine learning algorithm. 

_type your results and analysis here_


```{python}
# Include and execute your code here
df = data[['livearea', 'finbsmnt', 'basement', 'before1980', 'yrbuilt', 'stories', 'abstrprd', 'totunits', 'nocars', 'numbdrm', 'numbaths', 'sprice', 'deduct','netprice','tasp','smonth','syear','condition_AVG','condition_Excel','condition_Fair','condition_Good','condition_VGood','quality_A','quality_B','quality_C']]
 
df.head()

```

```{python}
LetsPlot.setup_html()
 
box_plot = ggplot(df, aes (x = "before1980", y= 'livearea')) + \
  geom_boxplot() + \
  ggtitle("Distribution of Home Size by 'before1980'") +\
  xlab("Built Before 1980") + \
  ylab("Living Area(sq ft)") + \
  coord_cartesian(ylim = (0, 5000))
 
box_plot.show()
df

```


## QUESTION|TASK 2

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”.__ Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.  

_type your results and analysis here_

```{python}
# Include and execute your code here
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn import metrics
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
 
 
columns_to_drop = ['before1980', 'parcel', 'yrbuilt']
df_cleaned = df.drop(columns=[col for col in columns_to_drop if col in df.columns])
 
X = df_cleaned
y = df['before1980']
 
categorical_columns = X.select_dtypes(include=['object']).columns
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_columns)
    ], remainder='passthrough'
)
 
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])
 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
 
pipeline.fit(X_train, y_train)
 
y_pred = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
 
print(f"Accuracy: {accuracy*100:.2f}%")
print(metrics.classification_report(y_test, y_pred))
 
importances = pipeline.named_steps['classifier'].feature_importances_
print("Feature importances:", importances)

```


## QUESTION|TASK 3

__Justify your classification model by discussing the most important features selected by your model.__ This discussion should include a feature importance chart and a description of the features. 

_type your results and analysis here_

```{python}
# Include and execute your code here

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import pandas as pd
 
columns_to_drop = ['before1980', 'parcel', 'yrbuilt']
df_cleaned = df.drop(columns=[col for col in columns_to_drop if col in df.columns])
 
X = df_cleaned
y = df['before1980']
 
categorical_columns = X.select_dtypes(include=['object']).columns
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)
    ], remainder='passthrough'
)
 
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=2))
])
 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)
 
pipeline.fit(X_train, y_train)
 
encoded_feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()
all_feature_names = list(encoded_feature_names)
 
feature_importances = pd.DataFrame({
    'Feature': all_feature_names,
    'Importance': pipeline.named_steps['classifier'].feature_importances_
})
 
 
LetsPlot.setup_html()
 
feature_importances = feature_importances.sort_values(by='Importance',ascending = True)
 
ggplot(feature_importances)+\
  geom_bar(aes(x ='Feature', y ='Importance'),stat = 'identity', fill = 'blue' )+\
  ggtitle('Feature Importance in Random Forest Classifiet(All Features)')+\
  xlab('Feature')+\
  ylab('Feature')+\
  coord_flip()

```


## QUESTION|TASK 4

__Describe the quality of your classification model using 2-3 different evaluation metrics.__ You also need to explain how to interpret each of the evaluation metrics you use.  

_type your results and analysis here_

```{python}
# Include and execute your code here



```

---

## STRETCH QUESTION|TASK 1

__Repeat the classification model using 3 different algorithms.__ Display their Feature Importance, and Decision Matrix. Explian the differences between the models and which one you would recommend to the Client.   

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 2

__Join the `dwellings_neighborhoods_ml.csv` data to the `dwelling_ml.csv` on the `parcel` column to create a new dataset. Duplicate the code for the stretch question above and update it to use this data.__ Explain the differences and if this changes the model you recomend to the Client.   

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 3

__Can you build a model that predicts the year a house was built?__ Explain the model and the evaluation metrics you would use to determine if the model is good.  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---
